{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36e8a713-3030-4772-ac5a-da0347fef981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reboot-student/Desktop/ProyectoPersonality/mbti_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-06-02 14:31:38.996759: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-02 14:31:38.997308: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-02 14:31:38.999634: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-02 14:31:39.005651: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748871099.016156   31539 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748871099.019053   31539 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748871099.027357   31539 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748871099.027366   31539 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748871099.027368   31539 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748871099.027368   31539 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-02 14:31:39.030255: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a70fb17-2eef-4171-b01a-4d941cbe5a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Limpieza de texto ---\n",
    "def limpiar(texto):\n",
    "    texto = re.sub(r\"http\\S+\", \"\", texto)\n",
    "    texto = re.sub(r\"\\|\\|\\|\", \" \", texto)\n",
    "    texto = re.sub(r\"[^A-Za-z\\s]\", \"\", texto)\n",
    "    texto = re.sub(r\"\\s+\", \" \", texto)\n",
    "    return texto.lower().strip()\n",
    "\n",
    "# --- Convertir etiquetas MBTI a binario ---\n",
    "def desglosar_mbti(tipo):\n",
    "    return {\n",
    "        \"IE\": 1 if tipo[0] == \"I\" else 0,\n",
    "        \"NS\": 1 if tipo[1] == \"N\" else 0,\n",
    "        \"FT\": 1 if tipo[2] == \"F\" else 0,\n",
    "        \"PJ\": 1 if tipo[3] == \"P\" else 0,\n",
    "    }\n",
    "\n",
    "# --- Carga el CSV ---\n",
    "df = pd.read_csv(\"mbti_1.csv\")\n",
    "\n",
    "# --- Limpia los textos ---\n",
    "df[\"clean_posts\"] = df[\"posts\"].apply(limpiar)\n",
    "\n",
    "# --- Desglosa las etiquetas ---\n",
    "mbti_binario = df[\"type\"].apply(desglosar_mbti).apply(pd.Series)\n",
    "df = pd.concat([df, mbti_binario], axis=1)\n",
    "\n",
    "# --- Divide en X y y ---\n",
    "X = df[\"clean_posts\"].tolist()\n",
    "y = df[[\"IE\", \"NS\", \"FT\", \"PJ\"]].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9df70333-8de3-4464-8b52-370381d2b40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1748871106.513807   31539 cuda_executor.cc:1228] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1748871106.514136   31539 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "868/868 [==============================] - 828s 947ms/step - loss: 0.5452 - accuracy: 0.6914 - val_loss: 0.5120 - val_accuracy: 0.7537\n",
      "Epoch 2/3\n",
      "868/868 [==============================] - 828s 954ms/step - loss: 0.4851 - accuracy: 0.7603 - val_loss: 0.5075 - val_accuracy: 0.7540\n",
      "Epoch 3/3\n",
      "868/868 [==============================] - 822s 947ms/step - loss: 0.4189 - accuracy: 0.8079 - val_loss: 0.5221 - val_accuracy: 0.7424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x7e66c8d07fe0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Separar train/test ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Tokenizador ---\n",
    "checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "def tokenize_texts(texts):\n",
    "    return tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors=\"tf\")\n",
    "\n",
    "train_encodings = tokenize_texts(X_train)\n",
    "test_encodings = tokenize_texts(X_test)\n",
    "\n",
    "# --- Dataset TensorFlow ---\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).batch(8)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(8)\n",
    "\n",
    "# --- Modelo ---\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=4, problem_type=\"multi_label_classification\")\n",
    "\n",
    "# --- Compilación ---\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "metrics = [tf.keras.metrics.BinaryAccuracy(name='accuracy')]\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "# --- Entrenamiento ---\n",
    "model.fit(train_dataset, validation_data=test_dataset, epochs=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2762c866-b055-4875-a441-e4eaaf97d75e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (2112639474.py, line 19)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint(predecir_personalidad(\"What the fuck did you just fucking say about me, you little bitch? I'll have you know I graduated top of my class in the Navy Seals, and I've been involved in numerous secret raids on Al-Quaeda, and I have over 300 confirmed kills. I am trained in gorilla warfare and I'm the top sniper in the entire US armed forces. You are nothing to me but just another target. I will wipe you the fuck out with precision the likes of which has never been seen before on this Earth, mark my fucking words. You think you can get away with saying that shit to me over the Internet? Think again, fucker. As we speak I am contacting my secret network of spies across the USA and your IP is being traced right now so you better prepare for the storm, maggot. The storm that wipes out the pathetic little thing you call your life. You're fucking dead, kid. I can be anywhere, anytime, and I can kill you in over seven hundred ways, and that's just with my bare hands. Not only am I extensively trained in unarmed combat, but I have access to the entire arsenal of the United States Marine Corps and I will use it to its full extent to wipe your miserable ass off the face of the continent, you little shit. If only you could have known what unholy retribution your little \"clever\" comment was about to bring down upon you, maybe you would have held your fucking tongue. But you couldn't, you didn't, and now you're paying the price, you goddamn idiot. I will shit fury all over you and you will drown in it. You're fucking dead, kiddo.\"))\u001b[39m\n                                ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Función para predecir ---\n",
    "def predecir_personalidad(texto):\n",
    "    inputs = tokenizer(texto, padding=True, truncation=True, max_length=128, return_tensors=\"tf\")\n",
    "    logits = model(inputs)[0]\n",
    "    probs = tf.sigmoid(logits)[0].numpy()\n",
    "    etiquetas = [\"Introvertido (I)\", \"Intuitivo (N)\", \"Sentimental (F)\", \"Perceptivo (P)\"]\n",
    "    resultado = []\n",
    "    for i, p in enumerate(probs):\n",
    "        if p > 0.5:\n",
    "            resultado.append(etiquetas[i])\n",
    "        else:\n",
    "            resultado.append(etiquetas[i].replace(\"(\", \"Extrovertido (E)\" if i==0 else\n",
    "                                                   \"Realista (S)\" if i==1 else\n",
    "                                                   \"Lógico (T)\" if i==2 else\n",
    "                                                   \"Juzgador (J)\"))\n",
    "    return \"Tu personalidad parece: \" + \", \".join(resultado)\n",
    "\n",
    "# --- Ejemplo ---\n",
    "print(predecir_personalidad(\"What the fuck did you just fucking say about me, you little bitch? I'll have you know I graduated top of my class in the Navy Seals, and I've been involved in numerous secret raids on Al-Quaeda, and I have over 300 confirmed kills. I am trained in gorilla warfare and I'm the top sniper in the entire US armed forces. You are nothing to me but just another target. I will wipe you the fuck out with precision the likes of which has never been seen before on this Earth, mark my fucking words. You think you can get away with saying that shit to me over the Internet? Think again, fucker. As we speak I am contacting my secret network of spies across the USA and your IP is being traced right now so you better prepare for the storm, maggot. The storm that wipes out the pathetic little thing you call your life. You're fucking dead, kid. I can be anywhere, anytime, and I can kill you in over seven hundred ways, and that's just with my bare hands. Not only am I extensively trained in unarmed combat, but I have access to the entire arsenal of the United States Marine Corps and I will use it to its full extent to wipe your miserable ass off the face of the continent, you little shit. If only you could have known what unholy retribution your little \"clever\" comment was about to bring down upon you, maybe you would have held your fucking tongue. But you couldn't, you didn't, and now you're paying the price, you goddamn idiot. I will shit fury all over you and you will drown in it. You're fucking dead, kiddo.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de2069b-8092-4731-b099-9492a3f731bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mbti_env)",
   "language": "python",
   "name": "mbti_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
